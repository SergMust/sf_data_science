{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задан DataFrame customer_df, содержащий столбцы:\n",
    "\n",
    "    cust_id — идентификатор клиента;\n",
    "    cust_age — возраст клиента (точкой отсчёта возраста считается 2021 год);\n",
    "    cust_sale — персональная скидка клиента;\n",
    "    cust_year_birth — год рождения клиента;\n",
    "    cust_order — сумма заказа клиента.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_df_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[39mreturn\u001b[39;00m df\u001b[39m.\u001b[39mdrop(col, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m \u001b[39mprint\u001b[39m(delete_columns(col \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mcust_sale\u001b[39m\u001b[39m'\u001b[39m], df \u001b[39m=\u001b[39m test_df_1))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_df_1' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "customer_df = pd.DataFrame({\n",
    "        'number': [0, 1, 2, 3, 4],\n",
    "        'cust_id': [128, 1201, 9832, 4392, 7472],\n",
    "        'cust_age': [13, 21, 19, 21, 60],\n",
    "        'cust_sale': [0, 0, 0.2, 0.15, 0.3],\n",
    "        'cust_year_birth': [2008, 2000, 2002, 2000, 1961],\n",
    "        'cust_order': [1400, 14142, 900, 1240, 8430]\n",
    "    })\n",
    "\n",
    "\n",
    "def delete_columns(df, col=[]):\n",
    "    for cc in col:\n",
    "        if cc not in df.columns:\n",
    "            return None\n",
    "    return df.drop(col, axis=1)\n",
    "print(delete_columns(col = ['cust_sale'], df = test_df_1))\n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задан DataFrame countries_df, содержащий следующие столбцы: название страны, население (population) в миллионах человек и площадь страны (square) в квадратных километрах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.93080566562001"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "countries_df = pd.DataFrame({\n",
    "    'country': ['Англия', 'Канада', 'США', 'Россия', 'Украина', 'Беларусь', 'Казахстан'],\n",
    "    'population': [56.29, 38.05, 322.28, 146.24, 45.5, 9.5, 17.04],\n",
    "    'square': [133396, 9984670, 9826630, 17125191, 603628, 207600, 2724902]\n",
    "})\n",
    "#display(countries_df)\n",
    "countries_df['population_density'] = (countries_df['population']*1000000) / countries_df['square']\n",
    "mean_population = countries_df['population_density'].mean()\n",
    "display(mean_population)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте в таблице melb_df признак WeekdaySale (день недели). Найдите, сколько объектов недвижимости было продано в выходные (суббота и воскресенье), результат занесите в переменную weekend_count. В качестве ответа введите результат вывода переменной weekend_count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12822"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "melb_data = pd.read_csv('data/melb_data_ps.csv', sep=',')\n",
    "melb_df = melb_data.copy()\n",
    "melb_df['Date'] = pd.to_datetime(melb_df['Date'], dayfirst=True)\n",
    "melb_df['WeekdaySale'] = melb_df['Date'].dt.dayofweek\n",
    "\n",
    "weekend_count = melb_df[melb_df['WeekdaySale'] == 5].shape[0] + melb_df[melb_df['WeekdaySale'] == 6].shape[0]\n",
    "display(weekend_count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Вводные данные для выполнения заданий 3.4-3.5\n",
    "\n",
    "Вам представлены данные (в формате csv) об отчётах очевидцев НЛО в США за период с 1930 по 2020 год.\n",
    "\n",
    "В данных есть следующие признаки:\n",
    "\n",
    "        \"City\" — город, где был замечен НЛО;\n",
    "        \"Colors Reported\" — цвет объекта;\n",
    "        \"Shape Reported\" — форма объекта;\n",
    "        \"State\" — обозначение штата;\n",
    "        \"Time\" — время, когда был замечен НЛО (данные отсортированы от старых наблюдений к новым). \n",
    "\n",
    "Прочитайте данные, сделайте преобразование времени к формату datetime и выполните задания ниже.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Colors Reported</th>\n",
       "      <th>Shape Reported</th>\n",
       "      <th>State</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ithaca</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRIANGLE</td>\n",
       "      <td>NY</td>\n",
       "      <td>1930-01-06 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Willingboro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>NJ</td>\n",
       "      <td>1930-06-30 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Holyoke</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OVAL</td>\n",
       "      <td>CO</td>\n",
       "      <td>1931-02-15 14:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DISK</td>\n",
       "      <td>KS</td>\n",
       "      <td>1931-01-06 13:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New York Worlds Fair</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LIGHT</td>\n",
       "      <td>NY</td>\n",
       "      <td>1933-04-18 19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18236</th>\n",
       "      <td>Grant Park</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRIANGLE</td>\n",
       "      <td>IL</td>\n",
       "      <td>2000-12-31 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18237</th>\n",
       "      <td>Spirit Lake</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DISK</td>\n",
       "      <td>IA</td>\n",
       "      <td>2000-12-31 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18238</th>\n",
       "      <td>Eagle River</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WI</td>\n",
       "      <td>2000-12-31 23:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18239</th>\n",
       "      <td>Eagle River</td>\n",
       "      <td>RED</td>\n",
       "      <td>LIGHT</td>\n",
       "      <td>WI</td>\n",
       "      <td>2000-12-31 23:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18240</th>\n",
       "      <td>Ybor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OVAL</td>\n",
       "      <td>FL</td>\n",
       "      <td>2000-12-31 23:59:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18241 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       City Colors Reported Shape Reported State  \\\n",
       "0                    Ithaca             NaN       TRIANGLE    NY   \n",
       "1               Willingboro             NaN          OTHER    NJ   \n",
       "2                   Holyoke             NaN           OVAL    CO   \n",
       "3                   Abilene             NaN           DISK    KS   \n",
       "4      New York Worlds Fair             NaN          LIGHT    NY   \n",
       "...                     ...             ...            ...   ...   \n",
       "18236            Grant Park             NaN       TRIANGLE    IL   \n",
       "18237           Spirit Lake             NaN           DISK    IA   \n",
       "18238           Eagle River             NaN            NaN    WI   \n",
       "18239           Eagle River             RED          LIGHT    WI   \n",
       "18240                  Ybor             NaN           OVAL    FL   \n",
       "\n",
       "                     Time  \n",
       "0     1930-01-06 22:00:00  \n",
       "1     1930-06-30 20:00:00  \n",
       "2     1931-02-15 14:00:00  \n",
       "3     1931-01-06 13:00:00  \n",
       "4     1933-04-18 19:00:00  \n",
       "...                   ...  \n",
       "18236 2000-12-31 23:00:00  \n",
       "18237 2000-12-31 23:00:00  \n",
       "18238 2000-12-31 23:45:00  \n",
       "18239 2000-12-31 23:45:00  \n",
       "18240 2000-12-31 23:59:00  \n",
       "\n",
       "[18241 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ufo_data = pd.read_csv('https://raw.githubusercontent.com/justmarkham/pandas-videos/master/data/ufo.csv')\n",
    "ufo_df = ufo_data.copy()\n",
    "\n",
    "ufo_df['Time'] = pd.to_datetime(ufo_df['Time'], dayfirst=True)\n",
    "display(ufo_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В каком году отмечается наибольшее количество случаев наблюдения НЛО в США?\n",
    "\n",
    "Подсказка (1 из 1): Чтобы выделить наиболее часто встречающийся год в таблице, необходимо сначала перевести столбец Time в формат datetime. После этого с помощью атрибута dt.year можно извлечь год наблюдения и найти его модальное значение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1999\n",
       "Name: Time, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ufo_data = pd.read_csv('https://raw.githubusercontent.com/justmarkham/pandas-videos/master/data/ufo.csv')\n",
    "ufo_df = ufo_data.copy()\n",
    "ufo_df['Time'] = pd.to_datetime(ufo_df['Time'], dayfirst=True)\n",
    "\n",
    "ufo_df['Time'] = ufo_df['Time'].dt.year\n",
    "\n",
    "ufo_df['Time'].value_counts(normalize=True)*100\n",
    "ufo_df['Time'].mode()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите средний интервал времени (в днях) между двумя последовательными случаями наблюдения НЛО в штате Невада (NV).\n",
    "\n",
    "Подсказка (1 из 1): Для удобства можно создать дополнительный столбец с датой Date, выделив атрибут datetime. После этого необходимо произвести фильтрацию и отобрать из данных только штат Невада. В отфильтрованных данных нужно вычислить разницу между двумя последовательными наблюдениями с помощью метода diff() и посчитать среднее количество дней между двумя наблюдениями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.92932862190813\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/justmarkham/pandas-videos/master/data/ufo.csv')\n",
    "df['Time'] = pd.to_datetime(df.Time)\n",
    "df['Date'] = df['Time'].dt.date\n",
    "print(df[df['State']=='NV']['Date'].diff().dt.days.mean())\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ранее, в задании 3.3, мы создали признак WeekdaySale в таблице melb_df — день недели продажи. Из полученных в задании результатов можно сделать вывод, что объекты недвижимости в Мельбурне продаются преимущественно по выходным (суббота и воскресенье).\n",
    "\n",
    "Напишите функцию get_weekend(weekday), которая принимает на вход элемент столбца WeekdaySale и возвращает 1, если день является выходным, и 0 — в противном случае, и создайте столбец  Weekend в таблице melb_df с помощью неё.\n",
    "\n",
    "Примените эту функцию к столбцу и вычислите среднюю цену объекта недвижимости, проданного в выходные дни. Результат округлите до целых."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1081198.64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "melb_data = pd.read_csv('data/melb_data_ps.csv', sep=',')\n",
    "melb_df = melb_data.copy()\n",
    "melb_df['Date'] = pd.to_datetime(melb_df['Date'], dayfirst=True)\n",
    "melb_df['WeekdaySale'] = melb_df['Date'].dt.dayofweek\n",
    "def get_weekend (weekday):\n",
    "    if weekday == 5 or weekday == 6:\n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "melb_df['Weekend'] = melb_df['WeekdaySale'].apply(get_weekend)\n",
    "print(round(melb_df[melb_df['Weekend']==1]['Price'].mean(), 2))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуйте столбец SellerG с наименованиями риелторских компаний в таблице melb_df следующим образом: оставьте в столбце только 49 самых популярных компаний, а остальные обозначьте как 'other'.\n",
    "\n",
    "Найдите, во сколько раз минимальная цена объектов недвижимости, проданных компанией 'Nelson', больше минимальной цены объектов, проданных компаниями, обозначенными как 'other'. Ответ округлите до десятых."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.297709923664122\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "melb_data = pd.read_csv('data/melb_data_ps.csv', sep=',')\n",
    "melb_df = melb_data.copy()\n",
    "seller = melb_df['SellerG']\n",
    "\n",
    "popular_seller = seller.value_counts().nlargest(49).index\n",
    "melb_df['SellerG'] = seller.apply(lambda x: x if x in popular_seller else 'other')\n",
    "\n",
    "min_price_nelson = round(melb_df[melb_df['SellerG']=='Nelson']['Price'].min(), 2)\n",
    "min_price_other = round(melb_df[melb_df['SellerG']=='other']['Price'].min(), 2)\n",
    "\n",
    "print(min_price_nelson / min_price_other)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представьте, что вы занимаетесь подготовкой данных о вакансиях с платформы hh.ru. В вашем распоряжении имеется таблица, в которой с помощью парсинга собраны резюме кандидатов. В этой таблице есть текстовый столбец «Опыт работы». Пример такого столбца представлен ниже в виде объекта Series. Структура текста в столбце фиксирована и не может измениться.\n",
    "\n",
    "Напишите функцию get_experience(arg), аргументом которой является строка столбца с опытом работы. Функция должна возвращать опыт работы в месяцах. Не забудьте привести результат к целому числу.\n",
    "\n",
    "Обратите внимание, что опыт работы может выражаться только в годах или только в месяцах. Учтите это при построении своей функции. Кроме того, учтите возможные вариации слов месяц (месяца, месяцев) и год (года, лет).\n",
    "\n",
    "Примените вашу функцию к Series experience_col с помощью метода apply()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experience(arg):\n",
    "    month_key_words = ['месяц', 'месяцев', 'месяца']\n",
    "    year_key_words = ['год', 'лет', 'года']\n",
    "    args_splited = arg.split(' ')\n",
    "    month = 0\n",
    "    year = 0\n",
    "    for i in range(len(args_splited)):\n",
    "        if args_splited[i] in month_key_words:\n",
    "            month = args_splited[i-1]\n",
    "        if args_splited[i] in year_key_words:\n",
    "            year = args_splited[i-1]\n",
    "    return int(year)*12 + int(month)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вашим заданием в этом модуле будет проанализировать и преобразовать данные о велопоездках клиентов компании Citi Bike (США), специализирующейся на прокате велосипедов."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Велосипед с каким идентификатором является самым популярным?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>start station id</th>\n",
       "      <th>start station name</th>\n",
       "      <th>start station latitude</th>\n",
       "      <th>start station longitude</th>\n",
       "      <th>end station id</th>\n",
       "      <th>end station name</th>\n",
       "      <th>end station latitude</th>\n",
       "      <th>end station longitude</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>usertype</th>\n",
       "      <th>birth year</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-09-01 00:00:05.2690</td>\n",
       "      <td>2018-09-01 00:27:20.6340</td>\n",
       "      <td>252.0</td>\n",
       "      <td>MacDougal St &amp; Washington Sq</td>\n",
       "      <td>40.732264</td>\n",
       "      <td>-73.998522</td>\n",
       "      <td>366.0</td>\n",
       "      <td>Clinton Ave &amp; Myrtle Ave</td>\n",
       "      <td>40.693261</td>\n",
       "      <td>-73.968896</td>\n",
       "      <td>25577</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-09-01 00:00:11.2810</td>\n",
       "      <td>2018-09-01 00:02:23.4810</td>\n",
       "      <td>314.0</td>\n",
       "      <td>Cadman Plaza West &amp; Montague St</td>\n",
       "      <td>40.693830</td>\n",
       "      <td>-73.990539</td>\n",
       "      <td>3242.0</td>\n",
       "      <td>Schermerhorn St &amp; Court St</td>\n",
       "      <td>40.691029</td>\n",
       "      <td>-73.991834</td>\n",
       "      <td>34377</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1969</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-09-01 00:00:20.6490</td>\n",
       "      <td>2018-09-01 00:55:58.5470</td>\n",
       "      <td>3142.0</td>\n",
       "      <td>1 Ave &amp; E 62 St</td>\n",
       "      <td>40.761227</td>\n",
       "      <td>-73.960940</td>\n",
       "      <td>3384.0</td>\n",
       "      <td>Smith St &amp; 3 St</td>\n",
       "      <td>40.678724</td>\n",
       "      <td>-73.995991</td>\n",
       "      <td>30496</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1975</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-09-01 00:00:21.7460</td>\n",
       "      <td>2018-09-01 00:07:38.5830</td>\n",
       "      <td>308.0</td>\n",
       "      <td>St James Pl &amp; Oliver St</td>\n",
       "      <td>40.713079</td>\n",
       "      <td>-73.998512</td>\n",
       "      <td>3690.0</td>\n",
       "      <td>Park Pl &amp; Church St</td>\n",
       "      <td>40.713342</td>\n",
       "      <td>-74.009355</td>\n",
       "      <td>28866</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1984</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-09-01 00:00:27.3150</td>\n",
       "      <td>2018-09-01 02:21:25.3080</td>\n",
       "      <td>345.0</td>\n",
       "      <td>W 13 St &amp; 6 Ave</td>\n",
       "      <td>40.736494</td>\n",
       "      <td>-73.997044</td>\n",
       "      <td>380.0</td>\n",
       "      <td>W 4 St &amp; 7 Ave S</td>\n",
       "      <td>40.734011</td>\n",
       "      <td>-74.002939</td>\n",
       "      <td>20943</td>\n",
       "      <td>Customer</td>\n",
       "      <td>1994</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  starttime                  stoptime  start station id  \\\n",
       "0  2018-09-01 00:00:05.2690  2018-09-01 00:27:20.6340             252.0   \n",
       "1  2018-09-01 00:00:11.2810  2018-09-01 00:02:23.4810             314.0   \n",
       "2  2018-09-01 00:00:20.6490  2018-09-01 00:55:58.5470            3142.0   \n",
       "3  2018-09-01 00:00:21.7460  2018-09-01 00:07:38.5830             308.0   \n",
       "4  2018-09-01 00:00:27.3150  2018-09-01 02:21:25.3080             345.0   \n",
       "\n",
       "                start station name  start station latitude  \\\n",
       "0     MacDougal St & Washington Sq               40.732264   \n",
       "1  Cadman Plaza West & Montague St               40.693830   \n",
       "2                  1 Ave & E 62 St               40.761227   \n",
       "3          St James Pl & Oliver St               40.713079   \n",
       "4                  W 13 St & 6 Ave               40.736494   \n",
       "\n",
       "   start station longitude  end station id            end station name  \\\n",
       "0               -73.998522           366.0    Clinton Ave & Myrtle Ave   \n",
       "1               -73.990539          3242.0  Schermerhorn St & Court St   \n",
       "2               -73.960940          3384.0             Smith St & 3 St   \n",
       "3               -73.998512          3690.0         Park Pl & Church St   \n",
       "4               -73.997044           380.0            W 4 St & 7 Ave S   \n",
       "\n",
       "   end station latitude  end station longitude  bikeid    usertype  \\\n",
       "0             40.693261             -73.968896   25577  Subscriber   \n",
       "1             40.691029             -73.991834   34377  Subscriber   \n",
       "2             40.678724             -73.995991   30496  Subscriber   \n",
       "3             40.713342             -74.009355   28866  Subscriber   \n",
       "4             40.734011             -74.002939   20943    Customer   \n",
       "\n",
       "   birth year  gender  \n",
       "0        1980       1  \n",
       "1        1969       0  \n",
       "2        1975       1  \n",
       "3        1984       2  \n",
       "4        1994       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "citi_bike = pd.read_csv('data/citibike-tripdata.csv', sep=',')\n",
    "bike_df = citi_bike.copy()\n",
    "display(bike_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33887\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "citi_bike = pd.read_csv('data/citibike-tripdata.csv', sep=',')\n",
    "bike_df = citi_bike.copy()\n",
    "bike_df['start station id'].value_counts(normalize=True) \n",
    "bike_df['bikeid'].value_counts(normalize=True)\n",
    "bike_df['usertype'].value_counts(normalize=True)\n",
    "print(bike_df['bikeid'].mode()[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какой тип клиентов (столбец usertype) является преобладающим — Subscriber или Customer? В качестве ответа запишите долю клиентов преобладающего типа среди общего количества клиентов. Ответ округлите до сотых."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77\n"
     ]
    }
   ],
   "source": [
    "mode_usertype = bike_df['usertype'].mode()[0]\n",
    "count_mode_user = bike_df[bike_df['usertype'] == mode_usertype].shape[0]\n",
    "print(round(count_mode_user / bike_df.shape[0], 2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Число уникальных стартовых и конечных стоянок, которыми воспользовались клиенты, не равны друг другу "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759\n",
      "765\n"
     ]
    }
   ],
   "source": [
    "print(bike_df['start station name'].nunique())\n",
    "print(bike_df['end station id'].nunique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рассматриваемые дни минимальный возраст клиента составлял 10 лет "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самой непопулярной стартовой стоянкой из тех, которыми воспользовались клиенты, является стоянка с названием \"Eastern Pkwy & Washington Ave\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Grand Army Plaza & Central Park S    0.006430\n",
       "Central Park S & 6 Ave               0.006367\n",
       "Pershing Square North                0.006247\n",
       "12 Ave & W 40 St                     0.006153\n",
       "West St & Chambers St                0.006120\n",
       "                                       ...   \n",
       "NYCBS Depot - GOW                    0.000050\n",
       "Franklin Ave & Empire Blvd           0.000037\n",
       "Railroad Ave & Kay Ave               0.000030\n",
       "47 Ave & Skillman Ave                0.000023\n",
       "Eastern Pkwy & Washington Ave        0.000020\n",
       "Name: start station name, Length: 759, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_df['start station name'].value_counts(normalize=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " D Наибольшее количество поездок завершается на стоянке под названием \"Liberty Light Rail\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "West St & Chambers St          0.006547\n",
       "12 Ave & W 40 St               0.006367\n",
       "Pershing Square North          0.006170\n",
       "Central Park S & 6 Ave         0.006097\n",
       "E 17 St & Broadway             0.006017\n",
       "                                 ...   \n",
       "Exchange Place                 0.000010\n",
       "Union St                       0.000003\n",
       "Warren St                      0.000003\n",
       "Montrose Ave & Bushwick Ave    0.000003\n",
       "Liberty Light Rail             0.000003\n",
       "Name: end station name, Length: 765, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_df['end station name'].value_counts(normalize=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первую очередь удалим лишнюю информацию из данных.\n",
    "\n",
    "В наших данных присутствуют столбцы, которые дублируют информацию друг о друге: это столбцы с идентификатором и названием стартовой и конечной стоянки. Удалите признаки идентификаторов стоянок. Сколько столбцов осталось?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300000 entries, 0 to 299999\n",
      "Data columns (total 12 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   starttime                300000 non-null  object \n",
      " 1   stoptime                 300000 non-null  object \n",
      " 2   start station name       299831 non-null  object \n",
      " 3   start station latitude   300000 non-null  float64\n",
      " 4   start station longitude  300000 non-null  float64\n",
      " 5   end station name         299831 non-null  object \n",
      " 6   end station latitude     300000 non-null  float64\n",
      " 7   end station longitude    300000 non-null  float64\n",
      " 8   bikeid                   300000 non-null  int64  \n",
      " 9   usertype                 300000 non-null  object \n",
      " 10  birth year               300000 non-null  int64  \n",
      " 11  gender                   300000 non-null  int64  \n",
      "dtypes: float64(4), int64(3), object(5)\n",
      "memory usage: 27.5+ MB\n"
     ]
    }
   ],
   "source": [
    "bike_df = bike_df.drop(['start station id', 'end station id' ], axis=1)\n",
    "bike_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Замените признак birth year на более понятный признак возраста клиента age. Годом отсчёта возраста выберите 2018 год. Столбец birth year удалите из таблицы. Сколько поездок совершено клиентами старше 60 лет?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11837"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "citi_bike = pd.read_csv('data/citibike-tripdata.csv', sep=',')\n",
    "bike_df = citi_bike.copy()\n",
    "bike_df = bike_df.drop(['start station id', 'end station id' ], axis=1)\n",
    "bike_df['starttime'] = pd.to_datetime(bike_df['starttime'], dayfirst=True)\n",
    "bike_df['stoptime'] = pd.to_datetime(bike_df['stoptime'], dayfirst=True)\n",
    "bike_df['Age'] = bike_df['starttime'].dt.year - bike_df['birth year']\n",
    "bike_df = bike_df.drop(['birth year' ], axis=1)\n",
    "bike_df[(bike_df['Age'] > 60)].shape[0]\n",
    "#bike_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте признак длительности поездки trip duration. Для этого вычислите интервал времени между временем окончания поездки (stoptime) и её началом (starttime). Сколько целых минут длилась поездка под индексом 3 в таблице?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('0 days 00:07:16.837000')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_df['trip duration'] = (bike_df['stoptime'] - bike_df['starttime'])\n",
    "bike_df.loc[3, 'trip duration']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте «признак-мигалку» weekend, который равен 1, если поездка начиналась в выходной день (суббота или воскресенье), и 0 — в противном случае. Выясните, сколько поездок начиналось в выходные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115135"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekday = bike_df['starttime'].dt.dayofweek\n",
    "bike_df['weekend'] = weekday.apply(lambda x: 1 if x ==5 or x == 6 else 0)\n",
    "bike_df['weekend'].sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте признак времени суток поездки time_of_day. Время суток будем определять из часа начала поездки. Условимся, что:\n",
    "\n",
    "    поездка совершается ночью (night), если её час приходится на интервал от 0 (включительно) до 6 (включительно) часов;\n",
    "    поездка совершается утром (morning), если её час приходится на интервал от 6 (не включительно) до 12 (включительно) часов;\n",
    "    поездка совершается днём (day), если её час приходится на интервал от 12 (не включительно) до 18 (включительно) часов;\n",
    "    поездка совершается вечером (evening), если её час приходится на интервал от 18 (не включительно) до 23 часов (включительно).\n",
    "\n",
    "Во сколько раз количество поездок, совершённых днём, больше, чем количество поездок, совёршенных ночью, за представленный в данных период времени? Ответ округлите до целых."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "citi_bike = pd.read_csv('data/citibike-tripdata.csv', sep=',')\n",
    "bike_df = citi_bike.copy()\n",
    "bike_df = bike_df.drop(['start station id', 'end station id' ], axis=1)\n",
    "bike_df['starttime'] = pd.to_datetime(bike_df['starttime'], dayfirst=True)\n",
    "bike_df['stoptime'] = pd.to_datetime(bike_df['stoptime'], dayfirst=True)\n",
    "bike_df['Age'] = bike_df['starttime'].dt.year - bike_df['birth year']\n",
    "bike_df = bike_df.drop(['birth year' ], axis=1)\n",
    "def get_time_of_day(time):\n",
    "    if 0 <= time <= 6:\n",
    "        return 'night'\n",
    "    elif 6 < time <= 12:\n",
    "        return 'morning'\n",
    "    elif 12 < time <= 18:\n",
    "        return 'day'\n",
    "    elif 18 < time <= 23:\n",
    "        return 'evening'\n",
    "\n",
    "bike_df['time_of_day'] = bike_df['starttime'].dt.hour.apply(get_time_of_day)\n",
    "a = bike_df[bike_df['time_of_day'] == 'day'].shape[0]\n",
    "b = bike_df[bike_df['time_of_day'] == 'night'].shape[0]\n",
    "print(round(a / b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "893682c4b29616811cfac52d908bc7079082a45dd0735f0cab17e1eaa77fff3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
